# -*- coding: utf-8 -*-
"""COVID-19 CLASSIFIER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F-8g_jq8HGbPAcKTf0qyDuQn1n2YL1hH
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt

"""! git clone https://github.com/education454/datasets.git"""

import os
base_dir = '/content/datasets/Data'
train_dir = os.path.join(base_dir,'train')
test_dir = os.path.join(base_dir,'test')
train_covid_dir = os.path.join(train_dir,'COVID19')
train_normal_dir = os.path.join(train_dir,'NORMAL')
test_covid_dir = os.path.join(test_dir,'COVID19')
test_normal_dir = os.path.join(test_dir,'NORMAL')

train_covid_names = os.listdir(train_covid_dir)
print(train_covid_names[:10])

train_normal_names = os.listdir(train_normal_dir)
print(train_normal_names[:10])

test_covid_names = os.listdir(test_covid_dir)
print(test_covid_names[:10])

test_normal_names = os.listdir(test_normal_dir)
print(test_normal_names[:10])

print('train_dataset_covid_images :',len(train_covid_names))
print('train_dataset_normal_images :',len(train_normal_names))
print('test_dataset_covid_images :',len(test_covid_names))
print('test_dataset_normal_images :',len(test_normal_names))
print('Total train images :', len(train_covid_names+train_normal_names))
print('Total test images :', len(test_covid_names+test_normal_names))

import matplotlib.image as mpimg
#plot a grid of 16 images (8 images of COVID 19 , 8 images of NORMAL)
 
#set the no.of rows and columns
nrows=4
ncols=4
#set the figure size
fig=plt.gcf() # plt.gcf gives us the reference to the current figure
fig.set_size_inches(12,12)
#get the filenames from the covid and the normal directories of the train datset
next_covid_pic = [os.path.join(train_covid_dir,fname) for fname in train_covid_names[0:8]]
next_normal_pic = [os.path.join(train_normal_dir,fname) for fname in train_normal_names[0:8]]
print(next_covid_pic)
print(next_normal_pic)

for i , img_path in enumerate(next_covid_pic+next_normal_pic):
  data= img_path.split('\\',6)
  sp=plt.subplot(nrows,ncols,i+1)
  sp.axis('off')
  img=mpimg.imread(img_path)
  sp.set_title(data,fontsize=10)
  plt.imshow(img,cmap='gray')
  plt.show()

train_datagen = ImageDataGenerator(rescale=1.0/255,
                                   validation_split=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   )
validation_datagen = ImageDataGenerator(rescale=1.0/255)
test_datagen = ImageDataGenerator(rescale=1.0/255)

train_generator= train_datagen.flow_from_directory(train_dir,
                                                   target_size=(150,150),
                                                   subset='training',
                                                   batch_size=32,
                                                   class_mode='binary')
validation_generator= train_datagen.flow_from_directory(train_dir,
                                                   target_size=(150,150),
                                                   subset='validation',
                                                   batch_size=32,
                                                   class_mode='binary')
test_generator= test_datagen.flow_from_directory(test_dir,
                                                   target_size=(150,150),
                                                   batch_size=32,
                                                   class_mode='binary')

train_generator.class_indices

train_generator.image_shape

model=Sequential()
# add convolutional layer
#filters, size of filters, padding , activation_function, input_shape
model.add(Conv2D(32,(5,5), padding='SAME', activation='relu', input_shape=(150,150,3)))
#pooling_layer
model.add(MaxPooling2D(pool_size=(2,2)))
#place a dropout layer
model.add(Dropout(0.5))
#add another convolutional layer
model.add(Conv2D(64,(5,5), padding='SAME', activation='relu'))
#pooling_layer
model.add(MaxPooling2D(pool_size=(2,2)))
#flatten the image to one dimensional array
model.add(Flatten())
# add a dense layer: amount of nodes, activation
model.add(Dense(256,activation='relu'))
# place a dropout layer
model.add(Dropout(0.5))   #0.5 dropout rate is recommended, half input nodes will be dropped at each update

model.add(Dense(1,activation='sigmoid'))
model.summary()

from tensorflow.keras.optimizers import Adam
model.compile(Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_generator,
                    epochs = 30,
                    validation_data = validation_generator,
                    validation_steps = 10)

history.history.keys()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training','validation'])
plt.title('Training and Validation loss')
plt.xlabel('epoch')

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training','validation'])
plt.title('Training and Validation accuracy')
plt.xlabel('epoch')

test_loss, test_acc = model.evaluate(test_generator)
print('test_acc :{} test loss :{}'.format(test_acc,test_loss))

import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()
for fn in uploaded.keys():
  path='/content/'+fn
  print(path)
  img = image.load_img(path , target_size=(150,150))
  x = image.img_to_array(img)
  x=np.expand_dims(x,axis=0)
  images = np.vstack([x])
  classes = model.predict(images,batch_size=10)
  print(fn)
  if classes==0:
       print('Covid19')
  else:
       print('Normal')